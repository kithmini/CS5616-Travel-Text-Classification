{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM-Classification.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjcR4xN40LR9"
      },
      "source": [
        "## Travel Domain Question Classification\n",
        "Following program classifies questions related to travel domain using LSTM."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6fOX0vb0QXI"
      },
      "source": [
        "Imports the required libraries and the data file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDRSTe9Ow-hZ",
        "outputId": "3686a4cf-902c-49a7-b81f-a9276b127ac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        }
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "nlp = spacy.load('en')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "!pip install fasttext\n",
        "\n",
        "print('----- Importing dataset -----')\n",
        "d_file = open('5000TravelQuestionsDataset.csv', encoding=\"latin-1\")\n",
        "\n",
        "df = pd.read_csv(d_file, header=None)\n",
        "df.columns = ['text', 'class1', 'class2']\n",
        "\n",
        "print ('Training Data : Imported Rows, Columns - ', df.shape)\n",
        "print ('Data Preview :')\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (50.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3043136 sha256=b6a1191eacd146bc9d221002a4920d3cd6f753d8e1ecd75b78c3fe79cd24018e\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n",
            "----- Importing dataset -----\n",
            "Training Data : Imported Rows, Columns -  (5000, 3)\n",
            "Data Preview :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the special things we (husband and me...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDSIG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are the companies which organize shark fe...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDOTH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Is it safe for female traveller to go alone to...</td>\n",
              "      <td>TGU</td>\n",
              "      <td>TGUHEA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What are the best places around Cape Town for ...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDSIG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are the best places to stay for a family ...</td>\n",
              "      <td>ACM</td>\n",
              "      <td>ACMOTH</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text class1  class2\n",
              "0  What are the special things we (husband and me...    TTD  TTDSIG\n",
              "1  What are the companies which organize shark fe...    TTD  TTDOTH\n",
              "2  Is it safe for female traveller to go alone to...    TGU  TGUHEA\n",
              "3  What are the best places around Cape Town for ...    TTD  TTDSIG\n",
              "4  What are the best places to stay for a family ...    ACM  ACMOTH"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPq7QFbd0CAe"
      },
      "source": [
        "The following section performs the text normalizing steps by converting text to lower case, removing leading and trailing whitespaces, removing stop words and also lematizing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3faWhRMxsGF"
      },
      "source": [
        "# Text normalization steps\n",
        "import string\n",
        "\n",
        "# Function to remove stop words\n",
        "def remove_stopwords(text):\n",
        "  text_tokens = nltk.word_tokenize(text) \n",
        "  filtered_sentence = [word for word in text_tokens if not word in stopwords.words()] \n",
        "  return \" \".join(filtered_sentence)\n",
        "\n",
        "# Converting to lower case \n",
        "df['processed_text'] = df['text'].str.lower()\n",
        "# Removing punctuations\n",
        "translator = str.maketrans('', '', string.punctuation)\n",
        "df['processed_text'] = df['processed_text'].str.translate(translator)\n",
        "# Removing leading ending white spaces\n",
        "df['processed_text'] = df['processed_text'].str.strip()\n",
        "# Remove stop words\n",
        "df['processed_text'] = df.processed_text.apply(remove_stopwords)\n",
        "\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "  lemmatized = [lemmatizer.lemmatize(word, pos=\"v\") for word in nltk.word_tokenize(text)]\n",
        "  return ' '.join(lemmatized)\n",
        "\n",
        "df['processed_text'] = df.processed_text.apply(lemmatize_text)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKmw3iwnQ9Sf",
        "outputId": "496ce272-2e46-454f-ee9a-234a7661bd8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# Removing leading ending white spaces\n",
        "df['class1'] = df['class1'].str.strip()\n",
        "df['class2'] = df['class2'].str.strip()\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the special things we (husband and me...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDSIG</td>\n",
              "      <td>special things husband 5 day stay cape town</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are the companies which organize shark fe...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDOTH</td>\n",
              "      <td>company organize shark feed events scuba divers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Is it safe for female traveller to go alone to...</td>\n",
              "      <td>TGU</td>\n",
              "      <td>TGUHEA</td>\n",
              "      <td>safe female traveller go alone cape town</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What are the best places around Cape Town for ...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDSIG</td>\n",
              "      <td>best place around cape town safari</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are the best places to stay for a family ...</td>\n",
              "      <td>ACM</td>\n",
              "      <td>ACMOTH</td>\n",
              "      <td>best place stay family stay away nightlife</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                   processed_text\n",
              "0  What are the special things we (husband and me...  ...      special things husband 5 day stay cape town\n",
              "1  What are the companies which organize shark fe...  ...  company organize shark feed events scuba divers\n",
              "2  Is it safe for female traveller to go alone to...  ...         safe female traveller go alone cape town\n",
              "3  What are the best places around Cape Town for ...  ...               best place around cape town safari\n",
              "4  What are the best places to stay for a family ...  ...       best place stay family stay away nightlife\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQI5I6-9ASTn"
      },
      "source": [
        "# Data Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azkwoBEKAVzg"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "y_encoded = le.fit_transform(df['class1'])\n",
        "y_encoded_1 = le.fit_transform(df['class2'])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y96ffyoPAmBp"
      },
      "source": [
        "max_words = 5000\n",
        "max_len = 25\n",
        "tok = Tokenizer(num_words=max_words, split=' ')\n",
        "tok.fit_on_texts(df.processed_text.values)\n",
        "seqs = tok.texts_to_sequences(df.processed_text.values)\n",
        "seqs_mat = sequence.pad_sequences(seqs,maxlen=max_len)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcKwFAqKAzn-",
        "outputId": "c007091e-59d5-492d-ea81-3da0442fd119",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "seqs_mat.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 25)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpiKnuzpBLqc"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-W_ePIxBNzT"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "def MODEL_LSTM():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(5000, 160, input_length=seqs_mat.shape[1]))\n",
        "    model.add(SpatialDropout1D(0.2))\n",
        "    model.add(LSTM(196, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(7, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEwkzENtBjVF",
        "outputId": "7d0ec924-3f31-42cc-e78a-c0019aafea07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "y_mat = pd.get_dummies(df['class1']).values\n",
        "y_mat.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yYgmvXkB4ch",
        "outputId": "e7a20183-56d3-49a3-d666-dd09ebe1794d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_mat_1 = pd.get_dummies(df['class2']).values\n",
        "y_mat_1.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 63)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgotUzN01IVU"
      },
      "source": [
        "# K-Fold classification and Accuracy Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LF8mqr4zbSp"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def accuracy_report(y_test, y_pred):\n",
        "    \n",
        "    print(classification_report(y_test,y_pred))\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)*100\n",
        "    print('Accuracy : %.3f' % acc)\n",
        "\n",
        "    f1 =  f1_score(y_test, y_pred, average='weighted')\n",
        "    print('F1 Score: %.3f' % f1)\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion Matrix: \\n{}\".format(cm))\n",
        "    \n",
        "    return f1\n",
        "    \n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQIDrr4Uej85"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def accuracy_summary(y_test, y_pred):\n",
        "    \n",
        "    acc = accuracy_score(y_test, y_pred)*100\n",
        "    print('Accuracy score: %.3f' % acc)\n",
        "\n",
        "    f1 =  f1_score(y_test, y_pred, average='weighted')\n",
        "    print('F1 Score: %.3f' % f1)\n",
        "\n",
        "    return f1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e1xYfnM1Tym",
        "outputId": "7a624621-3b73-4759-ae60-f7c0a469fd3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "fold = 0\n",
        "accuracies = []\n",
        "for train_index, test_index in cv.split(seqs):\n",
        "  fold += 1\n",
        "  X_train, X_test = seqs_mat[train_index], seqs_mat[test_index]\n",
        "  y_train, y_test = y_mat[train_index], y_mat[test_index]\n",
        "\n",
        "  model = MODEL_LSTM()\n",
        "  model.fit(X_train, y_train, epochs=5, batch_size=64,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
        "\n",
        "  predictions = model.predict(X_test)\n",
        "\n",
        "  fine_pred = [np.argmax(p) for p in predictions]\n",
        "  fine_gt = [np.argmax(p) for p in y_test]\n",
        "  f1 = accuracy_report(fine_pred, fine_gt)\n",
        "\n",
        "  accuracies.append(f1)\n",
        "  \n",
        "print(\"Mean {:.2f} Std {:.2f}\".format(np.mean(accuracies), np.std(accuracies)))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "64/64 [==============================] - 13s 196ms/step - loss: 1.7474 - accuracy: 0.2956 - val_loss: 1.7949 - val_accuracy: 0.2133\n",
            "Epoch 2/5\n",
            "64/64 [==============================] - 12s 193ms/step - loss: 1.0280 - accuracy: 0.6854 - val_loss: 1.3736 - val_accuracy: 0.5044\n",
            "Epoch 3/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 0.4850 - accuracy: 0.8472 - val_loss: 0.9878 - val_accuracy: 0.6667\n",
            "Epoch 4/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 0.2532 - accuracy: 0.9291 - val_loss: 0.9428 - val_accuracy: 0.6978\n",
            "Epoch 5/5\n",
            "64/64 [==============================] - 12s 191ms/step - loss: 0.1418 - accuracy: 0.9607 - val_loss: 0.8888 - val_accuracy: 0.7222\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.81      0.78        77\n",
            "           1       0.60      0.65      0.63        23\n",
            "           2       0.80      0.87      0.83        52\n",
            "           3       0.82      0.74      0.78       118\n",
            "           4       0.93      0.86      0.89       104\n",
            "           5       0.75      0.80      0.78       111\n",
            "           6       0.72      0.87      0.79        15\n",
            "\n",
            "    accuracy                           0.80       500\n",
            "   macro avg       0.77      0.80      0.78       500\n",
            "weighted avg       0.80      0.80      0.80       500\n",
            "\n",
            "Accuracy : 80.000\n",
            "F1 Score: 0.801\n",
            "Confusion Matrix: \n",
            "[[62  0  2  7  1  5  0]\n",
            " [ 2 15  2  0  0  3  1]\n",
            " [ 4  3 45  0  0  0  0]\n",
            " [ 5  1  5 87  3 15  2]\n",
            " [ 3  2  0  5 89  5  0]\n",
            " [ 5  4  2  6  3 89  2]\n",
            " [ 0  0  0  1  0  1 13]]\n",
            "Epoch 1/5\n",
            "64/64 [==============================] - 13s 200ms/step - loss: 1.7337 - accuracy: 0.2884 - val_loss: 1.6618 - val_accuracy: 0.4711\n",
            "Epoch 2/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 1.0080 - accuracy: 0.6689 - val_loss: 1.2550 - val_accuracy: 0.5578\n",
            "Epoch 3/5\n",
            "64/64 [==============================] - 12s 194ms/step - loss: 0.4574 - accuracy: 0.8506 - val_loss: 0.9995 - val_accuracy: 0.6622\n",
            "Epoch 4/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 0.2406 - accuracy: 0.9338 - val_loss: 1.1436 - val_accuracy: 0.6511\n",
            "Epoch 5/5\n",
            "64/64 [==============================] - 12s 191ms/step - loss: 0.1265 - accuracy: 0.9649 - val_loss: 0.8859 - val_accuracy: 0.7289\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.76      0.81        95\n",
            "           1       0.60      0.94      0.73        16\n",
            "           2       0.87      0.87      0.87        39\n",
            "           3       0.79      0.80      0.80       122\n",
            "           4       0.81      0.82      0.81        93\n",
            "           5       0.76      0.72      0.74       117\n",
            "           6       0.72      1.00      0.84        18\n",
            "\n",
            "    accuracy                           0.79       500\n",
            "   macro avg       0.78      0.84      0.80       500\n",
            "weighted avg       0.80      0.79      0.79       500\n",
            "\n",
            "Accuracy : 79.400\n",
            "F1 Score: 0.794\n",
            "Confusion Matrix: \n",
            "[[72  2  2  7  2  9  1]\n",
            " [ 0 15  0  0  1  0  0]\n",
            " [ 1  2 34  1  0  1  0]\n",
            " [ 4  0  1 98  9  9  1]\n",
            " [ 0  0  0  7 76  8  2]\n",
            " [ 5  6  2 11  6 84  3]\n",
            " [ 0  0  0  0  0  0 18]]\n",
            "Epoch 1/5\n",
            "64/64 [==============================] - 13s 199ms/step - loss: 1.7313 - accuracy: 0.3094 - val_loss: 1.7353 - val_accuracy: 0.2000\n",
            "Epoch 2/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 0.9845 - accuracy: 0.6723 - val_loss: 1.1489 - val_accuracy: 0.5978\n",
            "Epoch 3/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 0.4536 - accuracy: 0.8556 - val_loss: 0.8333 - val_accuracy: 0.7511\n",
            "Epoch 4/5\n",
            "64/64 [==============================] - 12s 193ms/step - loss: 0.2389 - accuracy: 0.9294 - val_loss: 0.8852 - val_accuracy: 0.7000\n",
            "Epoch 5/5\n",
            "64/64 [==============================] - 13s 196ms/step - loss: 0.1258 - accuracy: 0.9640 - val_loss: 0.8733 - val_accuracy: 0.7356\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.76      0.74        68\n",
            "           1       0.88      0.64      0.74        22\n",
            "           2       0.79      0.89      0.84        46\n",
            "           3       0.77      0.77      0.77       126\n",
            "           4       0.89      0.84      0.86       104\n",
            "           5       0.74      0.74      0.74       120\n",
            "           6       0.75      0.86      0.80        14\n",
            "\n",
            "    accuracy                           0.78       500\n",
            "   macro avg       0.79      0.79      0.78       500\n",
            "weighted avg       0.79      0.78      0.78       500\n",
            "\n",
            "Accuracy : 78.400\n",
            "F1 Score: 0.784\n",
            "Confusion Matrix: \n",
            "[[52  0  3  6  3  4  0]\n",
            " [ 0 14  2  0  2  3  1]\n",
            " [ 4  0 41  0  0  1  0]\n",
            " [ 9  0  1 97  4 15  0]\n",
            " [ 2  0  0  6 87  8  1]\n",
            " [ 5  2  5 15  2 89  2]\n",
            " [ 0  0  0  2  0  0 12]]\n",
            "Epoch 1/5\n",
            "64/64 [==============================] - 13s 196ms/step - loss: 1.7316 - accuracy: 0.2941 - val_loss: 1.8495 - val_accuracy: 0.2156\n",
            "Epoch 2/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 1.0326 - accuracy: 0.6640 - val_loss: 1.2971 - val_accuracy: 0.5222\n",
            "Epoch 3/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 0.4848 - accuracy: 0.8442 - val_loss: 0.9230 - val_accuracy: 0.6867\n",
            "Epoch 4/5\n",
            "64/64 [==============================] - 12s 195ms/step - loss: 0.2466 - accuracy: 0.9281 - val_loss: 0.8819 - val_accuracy: 0.7133\n",
            "Epoch 5/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 0.1445 - accuracy: 0.9563 - val_loss: 0.8632 - val_accuracy: 0.7222\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.76      0.81        79\n",
            "           1       0.50      0.75      0.60        16\n",
            "           2       0.88      0.89      0.88        56\n",
            "           3       0.75      0.78      0.77       119\n",
            "           4       0.88      0.82      0.85       110\n",
            "           5       0.79      0.80      0.80       105\n",
            "           6       0.82      0.93      0.87        15\n",
            "\n",
            "    accuracy                           0.81       500\n",
            "   macro avg       0.78      0.82      0.80       500\n",
            "weighted avg       0.81      0.81      0.81       500\n",
            "\n",
            "Accuracy : 80.600\n",
            "F1 Score: 0.808\n",
            "Confusion Matrix: \n",
            "[[60  3  3  8  0  5  0]\n",
            " [ 2 12  1  0  0  1  0]\n",
            " [ 1  3 50  0  0  2  0]\n",
            " [ 4  1  1 93 10  8  2]\n",
            " [ 1  0  0 13 90  6  0]\n",
            " [ 2  4  2 10  2 84  1]\n",
            " [ 0  1  0  0  0  0 14]]\n",
            "Epoch 1/5\n",
            "64/64 [==============================] - 13s 196ms/step - loss: 1.7432 - accuracy: 0.3049 - val_loss: 1.8282 - val_accuracy: 0.4400\n",
            "Epoch 2/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 0.9826 - accuracy: 0.6867 - val_loss: 1.0898 - val_accuracy: 0.6422\n",
            "Epoch 3/5\n",
            "64/64 [==============================] - 12s 190ms/step - loss: 0.5021 - accuracy: 0.8412 - val_loss: 1.0054 - val_accuracy: 0.6467\n",
            "Epoch 4/5\n",
            "64/64 [==============================] - 12s 191ms/step - loss: 0.2489 - accuracy: 0.9284 - val_loss: 0.9634 - val_accuracy: 0.7178\n",
            "Epoch 5/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 0.1491 - accuracy: 0.9558 - val_loss: 1.0155 - val_accuracy: 0.6644\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.62      0.70        74\n",
            "           1       0.60      0.69      0.64        26\n",
            "           2       0.86      0.75      0.80        56\n",
            "           3       0.82      0.64      0.72       162\n",
            "           4       0.71      0.96      0.82        81\n",
            "           5       0.51      0.67      0.58        87\n",
            "           6       0.73      0.79      0.76        14\n",
            "\n",
            "    accuracy                           0.71       500\n",
            "   macro avg       0.72      0.73      0.72       500\n",
            "weighted avg       0.74      0.71      0.71       500\n",
            "\n",
            "Accuracy : 71.200\n",
            "F1 Score: 0.713\n",
            "Confusion Matrix: \n",
            "[[ 46   1   1   5   2  19   0]\n",
            " [  1  18   0   0   1   5   1]\n",
            " [  2   5  42   3   0   4   0]\n",
            " [  3   1   5 103  22  25   3]\n",
            " [  0   1   0   1  78   1   0]\n",
            " [  5   3   1  13   7  58   0]\n",
            " [  0   1   0   0   0   2  11]]\n",
            "Epoch 1/5\n",
            "64/64 [==============================] - 13s 197ms/step - loss: 1.7400 - accuracy: 0.2881 - val_loss: 2.0169 - val_accuracy: 0.1156\n",
            "Epoch 2/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 1.0113 - accuracy: 0.6733 - val_loss: 1.2378 - val_accuracy: 0.5644\n",
            "Epoch 3/5\n",
            "64/64 [==============================] - 12s 191ms/step - loss: 0.4980 - accuracy: 0.8370 - val_loss: 1.0249 - val_accuracy: 0.6333\n",
            "Epoch 4/5\n",
            "64/64 [==============================] - 12s 195ms/step - loss: 0.2732 - accuracy: 0.9198 - val_loss: 0.9953 - val_accuracy: 0.6889\n",
            "Epoch 5/5\n",
            "64/64 [==============================] - 12s 195ms/step - loss: 0.1495 - accuracy: 0.9563 - val_loss: 0.8332 - val_accuracy: 0.7578\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.80      0.81        60\n",
            "           1       0.64      0.69      0.67        13\n",
            "           2       0.92      0.78      0.84        59\n",
            "           3       0.70      0.87      0.78       120\n",
            "           4       0.91      0.84      0.87       119\n",
            "           5       0.76      0.68      0.72       113\n",
            "           6       0.89      1.00      0.94        16\n",
            "\n",
            "    accuracy                           0.80       500\n",
            "   macro avg       0.81      0.81      0.80       500\n",
            "weighted avg       0.81      0.80      0.80       500\n",
            "\n",
            "Accuracy : 80.000\n",
            "F1 Score: 0.801\n",
            "Confusion Matrix: \n",
            "[[ 48   1   0   6   0   5   0]\n",
            " [  1   9   1   0   0   2   0]\n",
            " [  2   0  46   4   3   4   0]\n",
            " [  2   0   1 104   2  10   1]\n",
            " [  0   0   0  15 100   3   1]\n",
            " [  6   4   2  19   5  77   0]\n",
            " [  0   0   0   0   0   0  16]]\n",
            "Epoch 1/5\n",
            "64/64 [==============================] - 13s 200ms/step - loss: 1.7399 - accuracy: 0.2936 - val_loss: 1.6833 - val_accuracy: 0.5178\n",
            "Epoch 2/5\n",
            "64/64 [==============================] - 12s 195ms/step - loss: 0.9600 - accuracy: 0.6933 - val_loss: 1.2378 - val_accuracy: 0.5511\n",
            "Epoch 3/5\n",
            "64/64 [==============================] - 12s 194ms/step - loss: 0.4669 - accuracy: 0.8519 - val_loss: 0.9111 - val_accuracy: 0.7267\n",
            "Epoch 4/5\n",
            "64/64 [==============================] - 12s 195ms/step - loss: 0.2357 - accuracy: 0.9363 - val_loss: 0.8037 - val_accuracy: 0.7489\n",
            "Epoch 5/5\n",
            "64/64 [==============================] - 12s 193ms/step - loss: 0.1376 - accuracy: 0.9588 - val_loss: 0.8159 - val_accuracy: 0.7244\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.77      0.79        94\n",
            "           1       0.44      0.69      0.54        16\n",
            "           2       0.81      0.85      0.83        41\n",
            "           3       0.74      0.79      0.76       103\n",
            "           4       0.91      0.84      0.87       106\n",
            "           5       0.78      0.73      0.75       127\n",
            "           6       0.67      0.77      0.71        13\n",
            "\n",
            "    accuracy                           0.78       500\n",
            "   macro avg       0.74      0.78      0.75       500\n",
            "weighted avg       0.79      0.78      0.78       500\n",
            "\n",
            "Accuracy : 78.200\n",
            "F1 Score: 0.785\n",
            "Confusion Matrix: \n",
            "[[72  2  2  7  1  9  1]\n",
            " [ 0 11  1  0  0  4  0]\n",
            " [ 3  1 35  1  0  1  0]\n",
            " [ 7  2  0 81  5  8  0]\n",
            " [ 4  1  1  7 89  4  0]\n",
            " [ 3  6  4 14  3 93  4]\n",
            " [ 0  2  0  0  0  1 10]]\n",
            "Epoch 1/5\n",
            "64/64 [==============================] - 13s 197ms/step - loss: 1.7476 - accuracy: 0.2877 - val_loss: 1.7703 - val_accuracy: 0.4778\n",
            "Epoch 2/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 1.0005 - accuracy: 0.6854 - val_loss: 1.1922 - val_accuracy: 0.6067\n",
            "Epoch 3/5\n",
            "64/64 [==============================] - 13s 197ms/step - loss: 0.4710 - accuracy: 0.8491 - val_loss: 0.9353 - val_accuracy: 0.6889\n",
            "Epoch 4/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 0.2602 - accuracy: 0.9262 - val_loss: 0.7847 - val_accuracy: 0.7711\n",
            "Epoch 5/5\n",
            "64/64 [==============================] - 12s 191ms/step - loss: 0.1460 - accuracy: 0.9563 - val_loss: 0.7040 - val_accuracy: 0.8000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.75      0.74        61\n",
            "           1       0.69      0.73      0.71        15\n",
            "           2       0.77      0.96      0.85        49\n",
            "           3       0.65      0.82      0.73        94\n",
            "           4       0.84      0.87      0.85       106\n",
            "           5       0.87      0.62      0.72       162\n",
            "           6       0.71      0.92      0.80        13\n",
            "\n",
            "    accuracy                           0.77       500\n",
            "   macro avg       0.75      0.81      0.77       500\n",
            "weighted avg       0.79      0.77      0.77       500\n",
            "\n",
            "Accuracy : 77.000\n",
            "F1 Score: 0.767\n",
            "Confusion Matrix: \n",
            "[[ 46   0   1   5   4   5   0]\n",
            " [  0  11   2   1   1   0   0]\n",
            " [  0   1  47   1   0   0   0]\n",
            " [  4   0   0  77   7   6   0]\n",
            " [  4   0   1   5  92   4   0]\n",
            " [  9   4  10  28   6 100   5]\n",
            " [  0   0   0   1   0   0  12]]\n",
            "Epoch 1/5\n",
            "64/64 [==============================] - 13s 196ms/step - loss: 1.7336 - accuracy: 0.3133 - val_loss: 1.7763 - val_accuracy: 0.1822\n",
            "Epoch 2/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 1.0110 - accuracy: 0.6644 - val_loss: 1.1685 - val_accuracy: 0.5800\n",
            "Epoch 3/5\n",
            "64/64 [==============================] - 12s 193ms/step - loss: 0.4646 - accuracy: 0.8558 - val_loss: 1.1400 - val_accuracy: 0.6378\n",
            "Epoch 4/5\n",
            "64/64 [==============================] - 12s 195ms/step - loss: 0.2411 - accuracy: 0.9316 - val_loss: 0.8879 - val_accuracy: 0.7467\n",
            "Epoch 5/5\n",
            "64/64 [==============================] - 12s 194ms/step - loss: 0.1272 - accuracy: 0.9630 - val_loss: 0.9615 - val_accuracy: 0.7156\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.68      0.74        84\n",
            "           1       0.39      0.88      0.54         8\n",
            "           2       0.85      0.85      0.85        54\n",
            "           3       0.76      0.78      0.77       123\n",
            "           4       0.86      0.90      0.88        91\n",
            "           5       0.76      0.72      0.74       128\n",
            "           6       0.79      0.92      0.85        12\n",
            "\n",
            "    accuracy                           0.78       500\n",
            "   macro avg       0.74      0.82      0.77       500\n",
            "weighted avg       0.79      0.78      0.78       500\n",
            "\n",
            "Accuracy : 78.200\n",
            "F1 Score: 0.783\n",
            "Confusion Matrix: \n",
            "[[57  2  5  6  1 13  0]\n",
            " [ 0  7  0  0  0  1  0]\n",
            " [ 1  3 46  2  0  2  0]\n",
            " [ 6  1  2 96  8 10  0]\n",
            " [ 0  0  0  7 82  2  0]\n",
            " [ 7  5  1 16  4 92  3]\n",
            " [ 0  0  0  0  0  1 11]]\n",
            "Epoch 1/5\n",
            "64/64 [==============================] - 13s 198ms/step - loss: 1.7259 - accuracy: 0.3111 - val_loss: 1.7834 - val_accuracy: 0.2578\n",
            "Epoch 2/5\n",
            "64/64 [==============================] - 12s 193ms/step - loss: 0.9966 - accuracy: 0.6751 - val_loss: 1.1872 - val_accuracy: 0.5889\n",
            "Epoch 3/5\n",
            "64/64 [==============================] - 12s 191ms/step - loss: 0.4788 - accuracy: 0.8462 - val_loss: 0.9837 - val_accuracy: 0.7067\n",
            "Epoch 4/5\n",
            "64/64 [==============================] - 12s 193ms/step - loss: 0.2564 - accuracy: 0.9244 - val_loss: 0.8110 - val_accuracy: 0.7333\n",
            "Epoch 5/5\n",
            "64/64 [==============================] - 12s 192ms/step - loss: 0.1450 - accuracy: 0.9617 - val_loss: 0.9762 - val_accuracy: 0.6622\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.76      0.75        75\n",
            "           1       0.61      1.00      0.76        14\n",
            "           2       0.82      0.89      0.85        55\n",
            "           3       0.84      0.68      0.75       138\n",
            "           4       0.92      0.87      0.90       103\n",
            "           5       0.69      0.77      0.73       102\n",
            "           6       0.76      1.00      0.87        13\n",
            "\n",
            "    accuracy                           0.79       500\n",
            "   macro avg       0.77      0.85      0.80       500\n",
            "weighted avg       0.80      0.79      0.79       500\n",
            "\n",
            "Accuracy : 79.200\n",
            "F1 Score: 0.792\n",
            "Confusion Matrix: \n",
            "[[57  0  5  4  2  7  0]\n",
            " [ 0 14  0  0  0  0  0]\n",
            " [ 2  1 49  2  1  0  0]\n",
            " [ 8  2  4 94  3 24  3]\n",
            " [ 0  1  0  7 90  4  1]\n",
            " [ 9  5  2  5  2 79  0]\n",
            " [ 0  0  0  0  0  0 13]]\n",
            "Mean 0.78 Std 0.03\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sgtMGOvyOtC"
      },
      "source": [
        "New model LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0l_sT6c_yKDe"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import SpatialDropout1D\n",
        "def NEW_MODEL_LSTM():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(5000, 160, input_length=seqs_mat_1.shape[1]))\n",
        "    model.add(SpatialDropout1D(0.2))\n",
        "    model.add(LSTM(196, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(63, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5VdU9ONrdY7",
        "outputId": "8c75b60b-961b-4d4a-dfda-66662a64dd8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "fold = 0\n",
        "accuracies = []\n",
        "for train_index, test_index in cv.split(seqs_1):\n",
        "  fold += 1\n",
        "  X_train, X_test = seqs_mat[train_index], seqs_mat[test_index]\n",
        "  y_train, y_test = y_mat_1[train_index], y_mat_1[test_index]\n",
        "\n",
        "  model = NEW_MODEL_LSTM()\n",
        "  model.fit(X_train, y_train, epochs=5, batch_size=128,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n",
        "\n",
        "  predictions = model.predict(X_test)\n",
        "\n",
        "  fine_pred = [np.argmax(p) for p in predictions]\n",
        "  fine_gt = [np.argmax(p) for p in y_test]\n",
        "  f1 = accuracy_report(fine_pred, fine_gt)\n",
        "\n",
        "  accuracies.append(f1)\n",
        "  \n",
        "print(\"Mean {:.2f} Std {:.2f}\".format(np.mean(accuracies), np.std(accuracies)))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "32/32 [==============================] - 11s 342ms/step - loss: 3.8070 - accuracy: 0.0748 - val_loss: 3.5477 - val_accuracy: 0.0111\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 11s 335ms/step - loss: 3.6491 - accuracy: 0.0931 - val_loss: 3.3855 - val_accuracy: 0.3089\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 11s 337ms/step - loss: 3.5072 - accuracy: 0.1363 - val_loss: 3.2090 - val_accuracy: 0.2822\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 11s 332ms/step - loss: 2.9229 - accuracy: 0.2985 - val_loss: 2.6768 - val_accuracy: 0.3778\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 11s 341ms/step - loss: 2.0471 - accuracy: 0.5410 - val_loss: 2.2830 - val_accuracy: 0.4778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.47      0.73      0.58        26\n",
            "           5       0.77      0.59      0.67        29\n",
            "           6       0.71      0.62      0.67         8\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.38      0.20      0.26        15\n",
            "           9       0.00      0.00      0.00         0\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       0.00      0.00      0.00         0\n",
            "          14       0.84      0.54      0.66        39\n",
            "          15       0.50      0.29      0.36         7\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         0\n",
            "          20       0.00      0.00      0.00         0\n",
            "          21       0.00      0.00      0.00         5\n",
            "          22       0.00      0.00      0.00         1\n",
            "          23       0.00      0.00      0.00         0\n",
            "          24       0.00      0.00      0.00         0\n",
            "          25       0.75      0.86      0.80         7\n",
            "          26       0.00      0.00      0.00         0\n",
            "          27       0.33      0.38      0.35         8\n",
            "          29       0.00      0.00      0.00         0\n",
            "          30       0.00      0.00      0.00         0\n",
            "          31       0.00      0.00      0.00         0\n",
            "          32       0.64      0.64      0.64        22\n",
            "          33       0.00      0.00      0.00         0\n",
            "          35       0.00      0.00      0.00         0\n",
            "          36       0.64      0.54      0.58        13\n",
            "          37       0.53      0.82      0.64        11\n",
            "          38       0.75      0.38      0.50        16\n",
            "          39       0.00      0.00      0.00         0\n",
            "          40       0.00      0.00      0.00         0\n",
            "          41       0.50      1.00      0.67         6\n",
            "          42       0.75      0.33      0.46         9\n",
            "          46       0.62      0.56      0.59        27\n",
            "          47       0.83      0.79      0.81        19\n",
            "          48       0.58      0.37      0.45        19\n",
            "          49       0.73      0.80      0.76        10\n",
            "          50       0.00      0.00      0.00         0\n",
            "          51       0.00      0.00      0.00         1\n",
            "          52       0.00      0.00      0.00         0\n",
            "          53       0.00      0.00      0.00         0\n",
            "          54       0.90      0.22      0.35        87\n",
            "          55       0.71      0.56      0.63        63\n",
            "          56       0.00      0.00      0.00         0\n",
            "          57       0.67      0.42      0.52        38\n",
            "          58       0.00      0.00      0.00         0\n",
            "          59       0.00      0.00      0.00         0\n",
            "          60       0.87      0.93      0.90        14\n",
            "          61       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.50       500\n",
            "   macro avg       0.25      0.22      0.23       500\n",
            "weighted avg       0.70      0.50      0.55       500\n",
            "\n",
            "Accuracy : 49.800\n",
            "F1 Score: 0.549\n",
            "Confusion Matrix: \n",
            "[[ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0 13  0]\n",
            " [ 0  0  0 ...  0  0  0]]\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 11s 349ms/step - loss: 3.8110 - accuracy: 0.0753 - val_loss: 3.4869 - val_accuracy: 0.3133\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 11s 339ms/step - loss: 3.6627 - accuracy: 0.0800 - val_loss: 3.5184 - val_accuracy: 0.1222\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 11s 336ms/step - loss: 3.5571 - accuracy: 0.1284 - val_loss: 3.2488 - val_accuracy: 0.2778\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 11s 336ms/step - loss: 3.0199 - accuracy: 0.2677 - val_loss: 2.8226 - val_accuracy: 0.3511\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 11s 335ms/step - loss: 2.1987 - accuracy: 0.4709 - val_loss: 2.5817 - val_accuracy: 0.4067\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.71      0.67      0.69        45\n",
            "           5       0.82      0.36      0.50        50\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.07      0.33      0.11         3\n",
            "           9       0.00      0.00      0.00         0\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          14       0.84      0.37      0.52        43\n",
            "          15       0.00      0.00      0.00         0\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         0\n",
            "          20       0.00      0.00      0.00         0\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.00      0.00      0.00         1\n",
            "          24       0.00      0.00      0.00         0\n",
            "          25       0.60      0.67      0.63         9\n",
            "          26       0.00      0.00      0.00         0\n",
            "          27       0.50      0.71      0.59         7\n",
            "          28       0.00      0.00      0.00         0\n",
            "          29       0.00      0.00      0.00         0\n",
            "          30       0.00      0.00      0.00         0\n",
            "          31       0.00      0.00      0.00         0\n",
            "          32       0.32      0.50      0.39        12\n",
            "          33       0.00      0.00      0.00         0\n",
            "          34       0.00      0.00      0.00         0\n",
            "          35       0.00      0.00      0.00         0\n",
            "          36       0.70      0.58      0.64        12\n",
            "          37       0.84      0.84      0.84        19\n",
            "          38       0.71      0.83      0.77         6\n",
            "          39       0.00      0.00      0.00         0\n",
            "          40       0.00      0.00      0.00         0\n",
            "          41       0.86      0.86      0.86         7\n",
            "          42       0.20      0.33      0.25         3\n",
            "          43       0.00      0.00      0.00         0\n",
            "          45       0.00      0.00      0.00         0\n",
            "          46       0.63      0.50      0.56        38\n",
            "          47       1.00      0.35      0.52        31\n",
            "          48       0.29      0.17      0.22        23\n",
            "          49       0.82      0.82      0.82        11\n",
            "          50       0.00      0.00      0.00         0\n",
            "          51       0.25      1.00      0.40         1\n",
            "          53       0.00      0.00      0.00         0\n",
            "          54       0.94      0.19      0.32        89\n",
            "          55       0.61      0.69      0.65        48\n",
            "          56       0.00      0.00      0.00         0\n",
            "          57       0.42      0.29      0.34        28\n",
            "          58       0.00      0.00      0.00         0\n",
            "          59       0.00      0.00      0.00         0\n",
            "          60       0.76      0.93      0.84        14\n",
            "          61       0.00      0.00      0.00         0\n",
            "          62       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.46       500\n",
            "   macro avg       0.22      0.21      0.20       500\n",
            "weighted avg       0.73      0.46      0.52       500\n",
            "\n",
            "Accuracy : 46.400\n",
            "F1 Score: 0.521\n",
            "Confusion Matrix: \n",
            "[[ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 13  0  1]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]]\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 11s 346ms/step - loss: 3.8069 - accuracy: 0.0768 - val_loss: 3.4489 - val_accuracy: 0.0178\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 11s 336ms/step - loss: 3.6532 - accuracy: 0.0891 - val_loss: 3.5252 - val_accuracy: 0.0133\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 11s 343ms/step - loss: 3.4706 - accuracy: 0.1511 - val_loss: 3.3428 - val_accuracy: 0.1556\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 11s 336ms/step - loss: 2.8214 - accuracy: 0.3015 - val_loss: 2.6396 - val_accuracy: 0.3911\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 11s 337ms/step - loss: 2.0143 - accuracy: 0.5240 - val_loss: 2.2692 - val_accuracy: 0.4578\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           4       0.76      0.39      0.51        57\n",
            "           5       0.43      0.72      0.54        18\n",
            "           6       0.50      0.60      0.55         5\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.50      0.40      0.44         5\n",
            "           9       0.00      0.00      0.00         0\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         0\n",
            "          14       0.85      0.60      0.70        47\n",
            "          15       0.50      0.07      0.12        14\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         0\n",
            "          20       0.00      0.00      0.00         0\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.17      0.17      0.17         6\n",
            "          24       0.00      0.00      0.00         0\n",
            "          25       1.00      0.43      0.61        23\n",
            "          26       0.00      0.00      0.00         0\n",
            "          27       0.59      0.39      0.47        33\n",
            "          28       0.00      0.00      0.00         0\n",
            "          29       0.00      0.00      0.00         0\n",
            "          30       0.00      0.00      0.00         0\n",
            "          31       0.00      0.00      0.00         0\n",
            "          32       0.47      0.35      0.40        23\n",
            "          33       0.00      0.00      0.00         0\n",
            "          35       0.00      0.00      0.00         2\n",
            "          36       0.80      0.57      0.67         7\n",
            "          37       0.95      0.71      0.82        28\n",
            "          38       0.40      0.50      0.44         8\n",
            "          39       0.00      0.00      0.00         0\n",
            "          40       0.00      0.00      0.00         0\n",
            "          41       0.55      1.00      0.71         6\n",
            "          42       0.50      0.20      0.29        15\n",
            "          45       0.00      0.00      0.00         0\n",
            "          46       0.55      0.38      0.44        32\n",
            "          47       0.94      0.76      0.84        21\n",
            "          48       0.40      0.67      0.50         9\n",
            "          49       0.91      0.59      0.71        17\n",
            "          50       0.00      0.00      0.00         0\n",
            "          51       0.17      1.00      0.29         1\n",
            "          52       0.00      0.00      0.00         0\n",
            "          53       0.00      0.00      0.00         0\n",
            "          54       0.67      0.74      0.70        19\n",
            "          55       0.62      0.51      0.56        61\n",
            "          56       0.00      0.00      0.00         0\n",
            "          57       0.52      0.50      0.51        24\n",
            "          58       0.00      0.00      0.00         0\n",
            "          60       0.81      0.68      0.74        19\n",
            "\n",
            "    accuracy                           0.51       500\n",
            "   macro avg       0.27      0.24      0.24       500\n",
            "weighted avg       0.68      0.51      0.56       500\n",
            "\n",
            "Accuracy : 50.600\n",
            "F1 Score: 0.561\n",
            "Confusion Matrix: \n",
            "[[ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 1  2 22 ...  3  0  0]\n",
            " ...\n",
            " [ 0  0  1 ... 12  1  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0 13]]\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 11s 342ms/step - loss: 3.7996 - accuracy: 0.0691 - val_loss: 3.4881 - val_accuracy: 0.0133\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 11s 334ms/step - loss: 3.6511 - accuracy: 0.0847 - val_loss: 3.4229 - val_accuracy: 0.3133\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 11s 334ms/step - loss: 3.5556 - accuracy: 0.1217 - val_loss: 3.3497 - val_accuracy: 0.2244\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 11s 334ms/step - loss: 2.9874 - accuracy: 0.2862 - val_loss: 2.7336 - val_accuracy: 0.3133\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 11s 333ms/step - loss: 2.0658 - accuracy: 0.5262 - val_loss: 2.0973 - val_accuracy: 0.5044\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           4       0.53      0.41      0.46        39\n",
            "           5       0.79      0.48      0.60        31\n",
            "           6       0.67      0.80      0.73        10\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.40      0.57      0.47         7\n",
            "           9       0.00      0.00      0.00         0\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       0.00      0.00      0.00         0\n",
            "          14       0.86      0.68      0.76        28\n",
            "          15       0.00      0.00      0.00         0\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         0\n",
            "          20       0.00      0.00      0.00         0\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.29      0.11      0.16        18\n",
            "          24       0.00      0.00      0.00         0\n",
            "          25       1.00      0.40      0.57        15\n",
            "          26       0.00      0.00      0.00         0\n",
            "          27       0.56      0.47      0.51        19\n",
            "          30       0.00      0.00      0.00         0\n",
            "          31       0.00      0.00      0.00         0\n",
            "          32       0.61      0.52      0.56        21\n",
            "          33       0.00      0.00      0.00         0\n",
            "          35       0.00      0.00      0.00         1\n",
            "          36       0.67      0.57      0.62        14\n",
            "          37       0.87      0.91      0.89        22\n",
            "          38       0.62      0.45      0.53        11\n",
            "          39       0.00      0.00      0.00         0\n",
            "          40       0.00      0.00      0.00         0\n",
            "          41       0.73      0.30      0.42        27\n",
            "          42       0.17      0.67      0.27         3\n",
            "          44       0.00      0.00      0.00         0\n",
            "          46       0.82      0.32      0.46        44\n",
            "          47       0.80      0.67      0.73        18\n",
            "          48       0.35      0.64      0.45        11\n",
            "          49       0.73      0.73      0.73        11\n",
            "          50       0.00      0.00      0.00         0\n",
            "          51       0.20      1.00      0.33         1\n",
            "          52       0.00      0.00      0.00         0\n",
            "          53       0.00      0.00      0.00         3\n",
            "          54       0.78      0.64      0.70        11\n",
            "          55       0.77      0.55      0.64        65\n",
            "          56       0.00      0.00      0.00         0\n",
            "          57       0.58      0.26      0.36        54\n",
            "          58       0.00      0.00      0.00         0\n",
            "          60       0.79      0.69      0.73        16\n",
            "          61       0.00      0.00      0.00         0\n",
            "          62       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.49       500\n",
            "   macro avg       0.27      0.23      0.23       500\n",
            "weighted avg       0.69      0.49      0.55       500\n",
            "\n",
            "Accuracy : 48.600\n",
            "F1 Score: 0.550\n",
            "Confusion Matrix: \n",
            "[[ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 1  0 16 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 11  0  2]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]]\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 11s 343ms/step - loss: 3.8130 - accuracy: 0.0674 - val_loss: 3.4385 - val_accuracy: 0.2956\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 11s 334ms/step - loss: 3.6508 - accuracy: 0.0825 - val_loss: 3.4129 - val_accuracy: 0.2956\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 11s 331ms/step - loss: 3.5664 - accuracy: 0.1348 - val_loss: 3.3191 - val_accuracy: 0.2756\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 11s 335ms/step - loss: 3.0767 - accuracy: 0.2630 - val_loss: 2.8554 - val_accuracy: 0.2733\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 11s 332ms/step - loss: 2.1646 - accuracy: 0.4953 - val_loss: 2.3220 - val_accuracy: 0.4356\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           4       0.54      0.33      0.41        43\n",
            "           5       0.80      0.32      0.46        37\n",
            "           6       0.43      0.75      0.55         4\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.38      0.50      0.43        10\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       0.00      0.00      0.00         0\n",
            "          14       0.81      0.52      0.63        25\n",
            "          15       0.43      1.00      0.60         3\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         0\n",
            "          20       0.00      0.00      0.00         0\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.00      0.00      0.00         0\n",
            "          24       0.00      0.00      0.00         1\n",
            "          25       0.86      0.35      0.50        17\n",
            "          26       0.00      0.00      0.00         0\n",
            "          27       0.18      0.67      0.29         6\n",
            "          29       0.00      0.00      0.00         0\n",
            "          30       0.00      0.00      0.00         0\n",
            "          31       0.00      0.00      0.00         0\n",
            "          32       0.53      0.20      0.29        41\n",
            "          33       0.00      0.00      0.00         0\n",
            "          35       0.25      0.13      0.17        15\n",
            "          36       0.62      0.56      0.59         9\n",
            "          37       1.00      0.95      0.98        21\n",
            "          38       0.80      0.57      0.67        14\n",
            "          39       0.00      0.00      0.00         0\n",
            "          40       0.17      0.25      0.20         4\n",
            "          41       0.58      0.78      0.67         9\n",
            "          42       0.83      0.67      0.74        15\n",
            "          46       0.61      0.79      0.69        24\n",
            "          47       0.82      1.00      0.90         9\n",
            "          48       0.31      0.40      0.35        10\n",
            "          49       0.83      0.56      0.67        18\n",
            "          50       0.00      0.00      0.00         0\n",
            "          51       0.38      0.75      0.50         4\n",
            "          52       0.00      0.00      0.00         0\n",
            "          53       0.00      0.00      0.00         0\n",
            "          54       0.79      0.30      0.43        50\n",
            "          55       0.57      0.61      0.59        49\n",
            "          57       0.72      0.23      0.35        56\n",
            "          58       0.00      0.00      0.00         0\n",
            "          59       0.00      0.00      0.00         0\n",
            "          60       0.46      1.00      0.63         6\n",
            "          62       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.46       500\n",
            "   macro avg       0.28      0.27      0.25       500\n",
            "weighted avg       0.66      0.46      0.50       500\n",
            "\n",
            "Accuracy : 46.000\n",
            "F1 Score: 0.505\n",
            "Confusion Matrix: \n",
            "[[ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 2  0 14 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  6  0]\n",
            " [ 0  0  0 ...  0  0  0]]\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 11s 344ms/step - loss: 3.8017 - accuracy: 0.0681 - val_loss: 3.5618 - val_accuracy: 0.0111\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 11s 335ms/step - loss: 3.6533 - accuracy: 0.0807 - val_loss: 3.5139 - val_accuracy: 0.0267\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 11s 334ms/step - loss: 3.5388 - accuracy: 0.1417 - val_loss: 3.3602 - val_accuracy: 0.0444\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 11s 345ms/step - loss: 2.9949 - accuracy: 0.2760 - val_loss: 2.8462 - val_accuracy: 0.3111\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 11s 335ms/step - loss: 2.1274 - accuracy: 0.5160 - val_loss: 2.2395 - val_accuracy: 0.4867\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           4       0.52      0.56      0.54        25\n",
            "           5       0.75      0.52      0.61        29\n",
            "           6       0.50      0.67      0.57         3\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.20      0.50      0.29         2\n",
            "           9       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       0.00      0.00      0.00         0\n",
            "          14       0.94      0.38      0.54        45\n",
            "          15       0.38      1.00      0.55         3\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         0\n",
            "          21       0.00      0.00      0.00         1\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.12      1.00      0.22         1\n",
            "          24       0.00      0.00      0.00         0\n",
            "          25       0.69      0.65      0.67        17\n",
            "          27       0.64      0.82      0.72        11\n",
            "          28       0.00      0.00      0.00         0\n",
            "          29       0.00      0.00      0.00         0\n",
            "          30       0.00      0.00      0.00         0\n",
            "          31       0.00      0.00      0.00         0\n",
            "          32       0.32      0.53      0.40        15\n",
            "          33       0.00      0.00      0.00         0\n",
            "          34       0.00      0.00      0.00         0\n",
            "          35       0.07      0.50      0.12         2\n",
            "          36       1.00      0.44      0.62         9\n",
            "          37       0.79      0.85      0.82        27\n",
            "          38       0.64      0.44      0.52        16\n",
            "          39       0.00      0.00      0.00         0\n",
            "          40       0.00      0.00      0.00         0\n",
            "          41       0.67      0.38      0.48        21\n",
            "          42       0.23      0.75      0.35         4\n",
            "          43       0.00      0.00      0.00         0\n",
            "          46       0.85      0.42      0.56        52\n",
            "          47       0.93      0.65      0.76        20\n",
            "          48       0.33      0.56      0.42         9\n",
            "          49       0.83      0.71      0.77        14\n",
            "          50       0.00      0.00      0.00         0\n",
            "          51       0.00      0.00      0.00         0\n",
            "          52       0.00      0.00      0.00         0\n",
            "          53       0.00      0.00      0.00         0\n",
            "          54       0.94      0.41      0.57        37\n",
            "          55       0.73      0.56      0.64        73\n",
            "          56       0.00      0.00      0.00         0\n",
            "          57       0.64      0.19      0.29        48\n",
            "          58       0.00      0.00      0.00         0\n",
            "          60       0.87      0.81      0.84        16\n",
            "          61       0.00      0.00      0.00         0\n",
            "          62       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.51       500\n",
            "   macro avg       0.26      0.26      0.23       500\n",
            "weighted avg       0.74      0.51      0.57       500\n",
            "\n",
            "Accuracy : 51.000\n",
            "F1 Score: 0.573\n",
            "Confusion Matrix: \n",
            "[[ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 13  0  1]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]]\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 11s 344ms/step - loss: 3.8139 - accuracy: 0.0765 - val_loss: 3.4083 - val_accuracy: 0.0133\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 11s 337ms/step - loss: 3.6484 - accuracy: 0.0756 - val_loss: 3.2596 - val_accuracy: 0.3222\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 11s 333ms/step - loss: 3.5334 - accuracy: 0.1435 - val_loss: 3.2769 - val_accuracy: 0.0889\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 11s 336ms/step - loss: 2.9077 - accuracy: 0.3005 - val_loss: 2.5625 - val_accuracy: 0.3578\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 11s 336ms/step - loss: 2.0657 - accuracy: 0.5143 - val_loss: 2.3426 - val_accuracy: 0.4378\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.71      0.43      0.54        79\n",
            "           5       0.41      0.37      0.39        19\n",
            "           6       0.67      0.67      0.67         9\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.11      1.00      0.20         1\n",
            "           9       0.00      0.00      0.00         0\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       0.00      0.00      0.00         0\n",
            "          14       0.94      0.25      0.39        60\n",
            "          15       0.00      0.00      0.00         1\n",
            "          16       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         0\n",
            "          20       0.00      0.00      0.00         0\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.00      0.00      0.00         5\n",
            "          24       0.00      0.00      0.00         0\n",
            "          25       0.60      0.20      0.30        15\n",
            "          26       0.00      0.00      0.00         0\n",
            "          27       0.60      0.35      0.44        17\n",
            "          29       0.00      0.00      0.00         0\n",
            "          30       0.00      0.00      0.00         0\n",
            "          31       0.00      0.00      0.00         0\n",
            "          32       0.33      0.36      0.34        14\n",
            "          33       0.00      0.00      0.00         0\n",
            "          35       0.00      0.00      0.00         0\n",
            "          36       0.75      0.86      0.80         7\n",
            "          37       0.82      0.70      0.76        20\n",
            "          38       1.00      0.55      0.71        11\n",
            "          39       0.00      0.00      0.00         0\n",
            "          40       0.00      0.00      0.00         0\n",
            "          41       0.64      0.88      0.74         8\n",
            "          42       0.62      0.40      0.48        20\n",
            "          43       0.00      0.00      0.00         0\n",
            "          45       0.00      0.00      0.00         0\n",
            "          46       0.89      0.31      0.46        52\n",
            "          47       0.77      0.62      0.69        16\n",
            "          48       0.22      0.50      0.31         8\n",
            "          49       0.80      0.57      0.67        14\n",
            "          50       0.00      0.00      0.00         0\n",
            "          51       0.12      1.00      0.22         1\n",
            "          53       0.00      0.00      0.00         0\n",
            "          54       0.61      0.64      0.62        22\n",
            "          55       0.70      0.47      0.56        70\n",
            "          56       0.00      0.00      0.00         0\n",
            "          57       0.52      0.62      0.57        24\n",
            "          58       0.00      0.00      0.00         0\n",
            "          59       0.00      0.00      0.00         0\n",
            "          60       0.78      1.00      0.88         7\n",
            "          61       0.00      0.00      0.00         0\n",
            "          62       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.45       500\n",
            "   macro avg       0.24      0.22      0.21       500\n",
            "weighted avg       0.70      0.45      0.52       500\n",
            "\n",
            "Accuracy : 45.200\n",
            "F1 Score: 0.521\n",
            "Confusion Matrix: \n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 7 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 11s 342ms/step - loss: 3.8191 - accuracy: 0.0773 - val_loss: 3.4405 - val_accuracy: 0.0111\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 11s 333ms/step - loss: 3.6610 - accuracy: 0.0852 - val_loss: 3.5361 - val_accuracy: 0.0111\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 11s 333ms/step - loss: 3.5808 - accuracy: 0.1286 - val_loss: 3.3843 - val_accuracy: 0.0822\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 11s 339ms/step - loss: 3.0932 - accuracy: 0.2494 - val_loss: 2.6889 - val_accuracy: 0.3578\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 11s 335ms/step - loss: 2.2503 - accuracy: 0.4817 - val_loss: 2.4534 - val_accuracy: 0.4333\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       0.00      0.00      0.00         0\n",
            "           4       0.90      0.29      0.43        91\n",
            "           5       0.78      0.37      0.50        38\n",
            "           6       0.27      1.00      0.43         3\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.57      0.80      0.67         5\n",
            "           9       0.00      0.00      0.00         0\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          13       0.00      0.00      0.00         0\n",
            "          14       0.70      0.55      0.62        38\n",
            "          15       0.12      0.50      0.20         2\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         0\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.00      0.00      0.00         0\n",
            "          24       0.00      0.00      0.00         0\n",
            "          25       0.67      0.67      0.67        12\n",
            "          26       0.00      0.00      0.00         0\n",
            "          27       0.38      0.60      0.46         5\n",
            "          28       0.00      0.00      0.00         0\n",
            "          30       0.00      0.00      0.00         0\n",
            "          32       0.14      0.18      0.15        17\n",
            "          33       0.00      0.00      0.00         0\n",
            "          35       0.29      1.00      0.44         2\n",
            "          36       0.75      0.69      0.72        13\n",
            "          37       0.80      0.50      0.62        24\n",
            "          38       0.67      1.00      0.80         6\n",
            "          39       0.00      0.00      0.00         0\n",
            "          40       0.00      0.00      0.00         0\n",
            "          41       0.86      0.67      0.75         9\n",
            "          42       0.17      0.67      0.27         3\n",
            "          43       0.00      0.00      0.00         0\n",
            "          46       0.86      0.44      0.58        43\n",
            "          47       0.87      0.72      0.79        18\n",
            "          48       0.20      0.75      0.32         4\n",
            "          49       0.60      0.80      0.69        15\n",
            "          50       0.00      0.00      0.00         0\n",
            "          51       0.00      0.00      0.00         0\n",
            "          52       0.00      0.00      0.00         0\n",
            "          53       0.00      0.00      0.00         0\n",
            "          54       0.71      0.37      0.49        27\n",
            "          55       0.71      0.41      0.52        82\n",
            "          56       0.00      0.00      0.00         0\n",
            "          57       0.44      0.44      0.44        32\n",
            "          58       0.00      0.00      0.00         0\n",
            "          59       0.00      0.00      0.00         0\n",
            "          60       0.83      0.91      0.87        11\n",
            "          61       0.00      0.00      0.00         0\n",
            "          62       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.47       500\n",
            "   macro avg       0.25      0.27      0.23       500\n",
            "weighted avg       0.72      0.47      0.54       500\n",
            "\n",
            "Accuracy : 47.000\n",
            "F1 Score: 0.535\n",
            "Confusion Matrix: \n",
            "[[ 0  0  0 ...  0  0  0]\n",
            " [ 4 26  1 ...  1  0  0]\n",
            " [ 1  0 14 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 10  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]]\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 11s 342ms/step - loss: 3.8095 - accuracy: 0.0768 - val_loss: 3.4297 - val_accuracy: 0.3178\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 11s 333ms/step - loss: 3.6579 - accuracy: 0.0867 - val_loss: 3.5205 - val_accuracy: 0.0156\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 11s 334ms/step - loss: 3.5487 - accuracy: 0.1262 - val_loss: 3.3439 - val_accuracy: 0.0289\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 11s 333ms/step - loss: 2.9645 - accuracy: 0.2941 - val_loss: 2.6788 - val_accuracy: 0.4200\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 11s 335ms/step - loss: 2.0332 - accuracy: 0.5299 - val_loss: 2.3357 - val_accuracy: 0.5044\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.81      0.38      0.52        66\n",
            "           5       0.48      0.63      0.55        19\n",
            "           6       0.67      0.44      0.53         9\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.12      0.50      0.20         2\n",
            "           9       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         0\n",
            "          13       0.00      0.00      0.00         0\n",
            "          14       0.86      0.36      0.51        50\n",
            "          15       0.25      0.50      0.33         4\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         0\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.27      1.00      0.43         3\n",
            "          24       0.00      0.00      0.00         0\n",
            "          25       0.88      0.54      0.67        13\n",
            "          26       0.00      0.00      0.00         0\n",
            "          27       0.47      0.53      0.50        17\n",
            "          28       0.00      0.00      0.00         0\n",
            "          29       0.00      0.00      0.00         0\n",
            "          30       0.00      0.00      0.00         0\n",
            "          31       0.00      0.00      0.00         0\n",
            "          32       0.45      0.53      0.49        17\n",
            "          33       0.00      0.00      0.00         0\n",
            "          35       0.00      0.00      0.00         1\n",
            "          36       0.77      0.91      0.83        11\n",
            "          37       0.81      0.81      0.81        26\n",
            "          38       0.67      0.57      0.62         7\n",
            "          39       0.00      0.00      0.00         0\n",
            "          40       0.50      0.67      0.57         3\n",
            "          41       0.75      0.82      0.78        11\n",
            "          42       1.00      0.75      0.86         8\n",
            "          43       0.00      0.00      0.00         0\n",
            "          45       0.00      0.00      0.00         0\n",
            "          46       0.66      0.54      0.59        35\n",
            "          47       0.83      0.48      0.61        21\n",
            "          48       0.38      0.30      0.33        10\n",
            "          49       0.75      0.52      0.62        23\n",
            "          50       0.00      0.00      0.00         0\n",
            "          51       0.00      0.00      0.00         0\n",
            "          53       0.00      0.00      0.00         0\n",
            "          54       0.67      0.60      0.63        20\n",
            "          55       0.74      0.49      0.59        81\n",
            "          56       0.00      0.00      0.00         0\n",
            "          57       0.46      0.40      0.43        30\n",
            "          58       0.00      0.00      0.00         0\n",
            "          59       0.00      0.00      0.00         0\n",
            "          60       0.90      0.69      0.78        13\n",
            "          62       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.52       500\n",
            "   macro avg       0.27      0.24      0.24       500\n",
            "weighted avg       0.71      0.52      0.58       500\n",
            "\n",
            "Accuracy : 51.800\n",
            "F1 Score: 0.579\n",
            "Confusion Matrix: \n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 9 2]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "Epoch 1/5\n",
            "32/32 [==============================] - 11s 341ms/step - loss: 3.8256 - accuracy: 0.0674 - val_loss: 3.4049 - val_accuracy: 0.3067\n",
            "Epoch 2/5\n",
            "32/32 [==============================] - 11s 335ms/step - loss: 3.6669 - accuracy: 0.0812 - val_loss: 3.4804 - val_accuracy: 0.0444\n",
            "Epoch 3/5\n",
            "32/32 [==============================] - 11s 333ms/step - loss: 3.5967 - accuracy: 0.1222 - val_loss: 3.2515 - val_accuracy: 0.2911\n",
            "Epoch 4/5\n",
            "32/32 [==============================] - 11s 333ms/step - loss: 3.1831 - accuracy: 0.2338 - val_loss: 2.8789 - val_accuracy: 0.3111\n",
            "Epoch 5/5\n",
            "32/32 [==============================] - 11s 331ms/step - loss: 2.4133 - accuracy: 0.4225 - val_loss: 2.4551 - val_accuracy: 0.4422\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           4       0.60      0.48      0.53        50\n",
            "           5       0.67      0.39      0.49        36\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.38      0.43      0.40         7\n",
            "           9       0.00      0.00      0.00         0\n",
            "          10       0.00      0.00      0.00         0\n",
            "          11       0.00      0.00      0.00         0\n",
            "          12       0.00      0.00      0.00         0\n",
            "          14       0.82      0.60      0.69        30\n",
            "          15       0.12      1.00      0.22         2\n",
            "          16       0.00      0.00      0.00         0\n",
            "          17       0.00      0.00      0.00         0\n",
            "          18       0.00      0.00      0.00         0\n",
            "          19       0.00      0.00      0.00         0\n",
            "          20       0.00      0.00      0.00         0\n",
            "          21       0.00      0.00      0.00         0\n",
            "          22       0.00      0.00      0.00         0\n",
            "          23       0.00      0.00      0.00         2\n",
            "          24       0.00      0.00      0.00         0\n",
            "          25       0.64      1.00      0.78         9\n",
            "          26       0.00      0.00      0.00         0\n",
            "          27       0.17      0.40      0.24         5\n",
            "          28       0.00      0.00      0.00         0\n",
            "          29       0.00      0.00      0.00         0\n",
            "          30       0.00      0.00      0.00         0\n",
            "          31       0.00      0.00      0.00         0\n",
            "          32       0.36      0.56      0.43         9\n",
            "          33       0.00      0.00      0.00         0\n",
            "          35       0.00      0.00      0.00         0\n",
            "          36       0.29      0.50      0.36         4\n",
            "          37       0.87      0.62      0.72        21\n",
            "          38       0.50      0.80      0.62         5\n",
            "          39       0.00      0.00      0.00         0\n",
            "          40       0.11      0.50      0.18         2\n",
            "          41       0.62      0.71      0.67         7\n",
            "          42       0.00      0.00      0.00         3\n",
            "          43       0.00      0.00      0.00         0\n",
            "          44       0.00      0.00      0.00         0\n",
            "          46       0.78      0.28      0.41        64\n",
            "          47       0.93      0.50      0.65        28\n",
            "          48       0.17      0.18      0.17        11\n",
            "          49       0.87      0.52      0.65        25\n",
            "          50       0.00      0.00      0.00         0\n",
            "          51       0.00      0.00      0.00         0\n",
            "          52       0.00      0.00      0.00         0\n",
            "          53       0.00      0.00      0.00         0\n",
            "          54       0.29      0.33      0.31        12\n",
            "          55       0.76      0.34      0.47       119\n",
            "          56       0.00      0.00      0.00         0\n",
            "          57       0.52      0.34      0.41        38\n",
            "          58       0.00      0.00      0.00         0\n",
            "          60       0.64      0.82      0.72        11\n",
            "          62       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.43       500\n",
            "   macro avg       0.20      0.20      0.18       500\n",
            "weighted avg       0.68      0.43      0.50       500\n",
            "\n",
            "Accuracy : 43.200\n",
            "F1 Score: 0.504\n",
            "Confusion Matrix: \n",
            "[[ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  1 24 ...  0  1  0]\n",
            " ...\n",
            " [ 0  0  0 ...  0  0  0]\n",
            " [ 0  0  0 ...  0  9  1]\n",
            " [ 0  0  0 ...  0  0  0]]\n",
            "Mean 0.54 Std 0.03\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}