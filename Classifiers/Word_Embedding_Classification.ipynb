{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word-Embedding-Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPb2GxAYAgD_"
      },
      "source": [
        "# Travel Domain Question Classification\n",
        "Following program classifies questions related to travel domain using fasttext word embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LC1ynoq5Av8b"
      },
      "source": [
        "Imports the required libraries and the data file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_M5Gfk1-MwN",
        "outputId": "cd022edc-09f1-4cbb-c521-26411e423c31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        }
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nlp = spacy.load('en')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "!pip install fasttext\n",
        "\n",
        "print('----- Importing dataset -----')\n",
        "d_file = open('5000TravelQuestionsDataset.csv', encoding=\"latin-1\")\n",
        "\n",
        "df = pd.read_csv(d_file, header=None)\n",
        "df.columns = ['text', 'class1', 'class2']\n",
        "\n",
        "print ('Training Data : Imported Rows, Columns - ', df.shape)\n",
        "print ('Data Preview :')\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.6.1)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (50.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3043117 sha256=38587789c4c9547f2ae45784ec729fcd081f77fa7e8b9bea68df635c35766338\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "Successfully built fasttext\n",
            "Installing collected packages: fasttext\n",
            "Successfully installed fasttext-0.9.2\n",
            "----- Importing dataset -----\n",
            "Training Data : Imported Rows, Columns -  (5000, 3)\n",
            "Data Preview :\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the special things we (husband and me...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDSIG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are the companies which organize shark fe...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDOTH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Is it safe for female traveller to go alone to...</td>\n",
              "      <td>TGU</td>\n",
              "      <td>TGUHEA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What are the best places around Cape Town for ...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDSIG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are the best places to stay for a family ...</td>\n",
              "      <td>ACM</td>\n",
              "      <td>ACMOTH</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text class1  class2\n",
              "0  What are the special things we (husband and me...    TTD  TTDSIG\n",
              "1  What are the companies which organize shark fe...    TTD  TTDOTH\n",
              "2  Is it safe for female traveller to go alone to...    TGU  TGUHEA\n",
              "3  What are the best places around Cape Town for ...    TTD  TTDSIG\n",
              "4  What are the best places to stay for a family ...    ACM  ACMOTH"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXmARsdQBmAD"
      },
      "source": [
        "The following section performs the text normalizing steps by converting text to lower case, removing leading and trailing whitespaces, removing stop words and also lematizing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9CP23LaB_Nb",
        "outputId": "b5061c1e-74dc-4829-ff38-4e3a66c2fc16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# Text normalization steps\n",
        "import string\n",
        "\n",
        "# Function to remove stop words\n",
        "def remove_stopwords(text):\n",
        "  text_tokens = nltk.word_tokenize(text) \n",
        "  filtered_sentence = [word for word in text_tokens if not word in stopwords.words()] \n",
        "  return \" \".join(filtered_sentence)\n",
        "\n",
        "# Converting to lower case \n",
        "df['processed_text'] = df['text'].str.lower()\n",
        "# Removing punctuations\n",
        "translator = str.maketrans('', '', string.punctuation)\n",
        "df['processed_text'] = df['processed_text'].str.translate(translator)\n",
        "# Removing leading ending white spaces\n",
        "df['processed_text'] = df['processed_text'].str.strip()\n",
        "# Remove stop words\n",
        "df['processed_text'] = df.processed_text.apply(remove_stopwords)\n",
        "\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_text(text):\n",
        "  lemmatized = [lemmatizer.lemmatize(word, pos=\"v\") for word in nltk.word_tokenize(text)]\n",
        "  return ' '.join(lemmatized)\n",
        "\n",
        "df['processed_text'] = df.processed_text.apply(lemmatize_text)\n",
        "\n",
        "# Removing leading ending white spaces\n",
        "df['class1'] = df['class1'].str.strip()\n",
        "df['class2'] = df['class2'].str.strip()\n",
        "\n",
        "df.head()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class1</th>\n",
              "      <th>class2</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What are the special things we (husband and me...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDSIG</td>\n",
              "      <td>special things husband 5 day stay cape town</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What are the companies which organize shark fe...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDOTH</td>\n",
              "      <td>company organize shark feed events scuba divers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Is it safe for female traveller to go alone to...</td>\n",
              "      <td>TGU</td>\n",
              "      <td>TGUHEA</td>\n",
              "      <td>safe female traveller go alone cape town</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>What are the best places around Cape Town for ...</td>\n",
              "      <td>TTD</td>\n",
              "      <td>TTDSIG</td>\n",
              "      <td>best place around cape town safari</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are the best places to stay for a family ...</td>\n",
              "      <td>ACM</td>\n",
              "      <td>ACMOTH</td>\n",
              "      <td>best place stay family stay away nightlife</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                   processed_text\n",
              "0  What are the special things we (husband and me...  ...      special things husband 5 day stay cape town\n",
              "1  What are the companies which organize shark fe...  ...  company organize shark feed events scuba divers\n",
              "2  Is it safe for female traveller to go alone to...  ...         safe female traveller go alone cape town\n",
              "3  What are the best places around Cape Town for ...  ...               best place around cape town safari\n",
              "4  What are the best places to stay for a family ...  ...       best place stay family stay away nightlife\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hk_3OslRsSIr"
      },
      "source": [
        "def tokenize(text):\n",
        "    temp = nlp(text)\n",
        "    return [str(token) for token in temp if not token.is_stop]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01z9toWvtQNO"
      },
      "source": [
        "tokenized = [tokenize(text) for text in df.processed_text]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYmwaBJ9vTCi"
      },
      "source": [
        "# FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1BTOZen4BCY",
        "outputId": "f692400d-c916-4c89-a754-73e4904dd443",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import fasttext.util\n",
        "\n",
        "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
        "ft = fasttext.load_model('cc.en.300.bin')\n",
        "\n",
        "ft.get_dimension()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.bin.gz\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4XX9qOR51sq"
      },
      "source": [
        "def get_sentence_embedding(wordlist):\n",
        "  embedding=ft.get_sentence_vector(wordlist)\n",
        "  return embedding"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdELPZfDo7xS"
      },
      "source": [
        "embeddings = [np.mean(np.array(list(map(get_sentence_embedding,token))),axis=0) for token in tokenized]\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_iaMlZ5dm0s",
        "outputId": "6a0ddd58-91b4-4116-905a-9cf0971d265a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# x_embed = [np.mean(np.array(list(map(get_sentence_embedding,token))),axis=0) for token in embeddings]\n",
        "x_encoded = np.array(embeddings)\n",
        "x_encoded.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-zOcYefeRf2"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "y_encoded = le.fit_transform(df['class1'])\n",
        "y_encoded_1 = le.fit_transform(df['class2'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdw9DuwK0_M9"
      },
      "source": [
        "# K-Fold classification and Accuracy Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEy2qzTPeeVK"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def calculate_accuracy(encoded_x, encoded_y):\n",
        "  cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
        "  fold = 0\n",
        "  accuracies = []\n",
        "  for train_index, test_index in cv.split(encoded_x):\n",
        "      fold += 1\n",
        "      X_train, X_test = encoded_x[train_index], encoded_x[test_index]\n",
        "      y_train, y_test = encoded_y[train_index], encoded_y[test_index]\n",
        "      SVM = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "      SVM.fit(X_train,y_train)\n",
        "      predictions_y = SVM.predict(X_test)\n",
        "      acc = accuracy_score(predictions_y, y_test)*100\n",
        "      accuracies.append(acc)\n",
        "      print(\"K-Fold: {} - {} - {:.2f}\".format(fold, \"Accuracy: \",acc))\n",
        "      \n",
        "  print(\"Mean {:.2f} Std {:.2f}\".format(np.mean(accuracies), np.std(accuracies)))\n",
        "  return y_test, predictions_y"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6Ef3Xwkfa5q"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def accuracy_report(y_test, y_pred):\n",
        "    \n",
        "    print(classification_report(y_test,y_pred))\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)*100\n",
        "    print('Accuracy : %.3f' % acc)\n",
        "\n",
        "    print('F1 Score: %.3f' % f1_score(y_test, y_pred, average='weighted'))\n",
        "    \n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion Matrix: \\n{}\".format(cm))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ircf1bZu5vW",
        "outputId": "c1222113-3179-4a84-efcb-97320b29f5ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_return = calculate_accuracy(x_encoded, y_encoded)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K-Fold: 1 - Accuracy:  - 75.80\n",
            "K-Fold: 2 - Accuracy:  - 77.00\n",
            "K-Fold: 3 - Accuracy:  - 76.40\n",
            "K-Fold: 4 - Accuracy:  - 77.60\n",
            "K-Fold: 5 - Accuracy:  - 77.60\n",
            "K-Fold: 6 - Accuracy:  - 77.40\n",
            "K-Fold: 7 - Accuracy:  - 75.20\n",
            "K-Fold: 8 - Accuracy:  - 78.00\n",
            "K-Fold: 9 - Accuracy:  - 78.40\n",
            "K-Fold: 10 - Accuracy:  - 79.00\n",
            "Mean 77.24 Std 1.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEnI3KTRfuUy",
        "outputId": "64de21d4-b989-4ac2-d355-962cbf75f4be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accuracy_report(y_return[0], y_return[1])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.86      0.79      0.82        76\n",
            "           2       0.80      0.35      0.48        23\n",
            "           3       0.94      0.82      0.87        60\n",
            "           4       0.78      0.76      0.77       112\n",
            "           6       0.86      0.88      0.87        98\n",
            "           7       0.64      0.82      0.72       114\n",
            "           9       1.00      0.82      0.90        17\n",
            "\n",
            "    accuracy                           0.79       500\n",
            "   macro avg       0.84      0.75      0.78       500\n",
            "weighted avg       0.80      0.79      0.79       500\n",
            "\n",
            "Accuracy : 79.000\n",
            "F1 Score: 0.789\n",
            "Confusion Matrix: \n",
            "[[60  0  2  6  0  8  0]\n",
            " [ 1  8  0  3  1 10  0]\n",
            " [ 1  1 49  2  0  7  0]\n",
            " [ 3  0  0 85  6 18  0]\n",
            " [ 0  1  0  3 86  8  0]\n",
            " [ 4  0  1  9  7 93  0]\n",
            " [ 1  0  0  1  0  1 14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaOF9TdmvlS3",
        "outputId": "b3024f15-6ef1-4dd1-c13a-427bb618c977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_return = calculate_accuracy(x_encoded, y_encoded_1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K-Fold: 1 - Accuracy:  - 53.80\n",
            "K-Fold: 2 - Accuracy:  - 52.20\n",
            "K-Fold: 3 - Accuracy:  - 52.80\n",
            "K-Fold: 4 - Accuracy:  - 52.40\n",
            "K-Fold: 5 - Accuracy:  - 52.20\n",
            "K-Fold: 6 - Accuracy:  - 52.00\n",
            "K-Fold: 7 - Accuracy:  - 50.20\n",
            "K-Fold: 8 - Accuracy:  - 53.40\n",
            "K-Fold: 9 - Accuracy:  - 53.80\n",
            "K-Fold: 10 - Accuracy:  - 52.20\n",
            "Mean 52.50 Std 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4G6hMhXywgpg",
        "outputId": "77fca74a-3b70-4a17-d063-0fe341352145",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "accuracy_report(y_return[0], y_return[1])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           3       0.00      0.00      0.00         2\n",
            "           5       0.00      0.00      0.00         8\n",
            "           7       0.48      0.70      0.57        40\n",
            "           8       0.47      0.38      0.42        21\n",
            "          10       1.00      0.20      0.33         5\n",
            "          11       0.00      0.00      0.00         1\n",
            "          12       1.00      0.38      0.55         8\n",
            "          13       0.00      0.00      0.00         2\n",
            "          14       0.00      0.00      0.00         2\n",
            "          15       0.00      0.00      0.00         7\n",
            "          16       0.00      0.00      0.00         3\n",
            "          18       0.50      0.82      0.62        22\n",
            "          20       1.00      0.56      0.72        16\n",
            "          21       0.00      0.00      0.00         3\n",
            "          22       0.00      0.00      0.00         2\n",
            "          23       0.50      1.00      0.67         1\n",
            "          24       0.00      0.00      0.00         4\n",
            "          25       0.00      0.00      0.00         4\n",
            "          26       0.00      0.00      0.00         8\n",
            "          27       0.50      0.33      0.40         6\n",
            "          28       0.67      0.22      0.33         9\n",
            "          29       0.00      0.00      0.00         4\n",
            "          30       1.00      0.93      0.96        14\n",
            "          31       0.00      0.00      0.00         2\n",
            "          33       0.80      0.33      0.47        12\n",
            "          34       0.00      0.00      0.00         1\n",
            "          35       0.00      0.00      0.00         1\n",
            "          36       1.00      0.50      0.67         4\n",
            "          37       0.00      0.00      0.00         2\n",
            "          38       0.71      0.36      0.48        14\n",
            "          40       0.00      0.00      0.00         5\n",
            "          42       0.25      0.20      0.22         5\n",
            "          43       1.00      1.00      1.00         7\n",
            "          44       0.71      0.80      0.75        15\n",
            "          45       0.83      0.62      0.71         8\n",
            "          46       0.00      0.00      0.00         3\n",
            "          47       0.75      0.33      0.46         9\n",
            "          49       1.00      0.88      0.93         8\n",
            "          50       0.38      0.60      0.46         5\n",
            "          51       0.00      0.00      0.00         1\n",
            "          52       0.00      0.00      0.00         1\n",
            "          54       0.38      0.65      0.48        17\n",
            "          55       0.00      0.00      0.00         6\n",
            "          56       0.78      0.93      0.85        15\n",
            "          57       0.83      0.42      0.56        12\n",
            "          59       0.79      0.73      0.76        15\n",
            "          60       0.00      0.00      0.00         2\n",
            "          61       0.83      0.71      0.77         7\n",
            "          62       0.00      0.00      0.00         1\n",
            "          63       0.25      0.06      0.10        17\n",
            "          65       0.38      0.57      0.46        14\n",
            "          67       0.32      0.93      0.48        54\n",
            "          69       0.00      0.00      0.00         2\n",
            "          70       0.63      0.48      0.55        25\n",
            "          72       0.00      0.00      0.00         1\n",
            "          74       0.77      0.83      0.80        12\n",
            "          75       0.00      0.00      0.00         2\n",
            "          77       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.52       500\n",
            "   macro avg       0.35      0.30      0.30       500\n",
            "weighted avg       0.51      0.52      0.48       500\n",
            "\n",
            "Accuracy : 52.200\n",
            "F1 Score: 0.476\n",
            "Confusion Matrix: \n",
            "[[ 0  0  2 ...  0  0  0]\n",
            " [ 0  0  2 ...  0  0  0]\n",
            " [ 0  0 28 ...  0  0  0]\n",
            " ...\n",
            " [ 0  0  0 ... 10  0  0]\n",
            " [ 0  0  0 ...  2  0  0]\n",
            " [ 0  0  0 ...  1  0  0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}